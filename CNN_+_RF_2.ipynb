{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chirag-79/hms/blob/main/CNN_%2B_RF_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKLyuRFi8x5c"
      },
      "source": [
        "#  Step 1: Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "srI7fM--6mTB",
        "outputId": "4d4467f9-24b6-4bf4-f176-b973fb2e5737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/train_images.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1402677258.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Extract images only if they are not already extracted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_FOLDER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZIP_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_FOLDER\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/zipfile/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1350\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/train_images.zip'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "DATA_CSV = \"/content/train.csv\"  # CSV containing 'id_code' and 'diagnosis'\n",
        "ZIP_PATH = \"/content/drive/MyDrive/train_images.zip\"\n",
        "IMAGE_FOLDER = \"/content/train_images\"\n",
        "\n",
        "# Extract images only if they are not already extracted\n",
        "if not os.path.exists(IMAGE_FOLDER):\n",
        "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
        "        zip_ref.extractall(IMAGE_FOLDER)\n",
        "\n",
        "# Load dataset\n",
        "full_df = pd.read_csv(DATA_CSV)\n",
        "\n",
        "# Ensure correct file format\n",
        "full_df[\"id_code\"] = full_df[\"id_code\"].astype(str) + \".png\"\n",
        "labels = full_df[\"diagnosis\"]\n",
        "\n",
        "# Encode labels\n",
        "unique_labels = sorted(labels.unique())  # Unique clsses\n",
        "label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "labels_encoded = np.array([label_to_index[label] for label in labels])\n",
        "\n",
        "# Split dataset: Train (70%), Validation (15%), Test (15%)\n",
        "train_ids, temp_ids, y_train, y_temp = train_test_split(full_df[\"id_code\"], labels_encoded, test_size=0.3, random_state=42)\n",
        "val_ids, test_ids, y_val, y_test = train_test_split(temp_ids, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Image size\n",
        "IMG_HEIGHT, IMG_WIDTH = 128, 128  # Adjust based on dataset\n",
        "\n",
        "# Function to load images, skipping missing ones\n",
        "def load_images(image_ids, image_folder):\n",
        "    images, valid_labels = [], []\n",
        "    for img_id in image_ids:\n",
        "        img_path = os.path.join(image_folder, img_id)\n",
        "        if os.path.exists(img_path):  # Only process existing images\n",
        "            img = load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))  # Resize\n",
        "            img = img_to_array(img) / 255.0  # Normalize\n",
        "            images.append(img)\n",
        "        else:\n",
        "            print(f\"Warning: Image {img_path} not found!\")\n",
        "\n",
        "    return np.array(images)\n",
        "\n",
        "# Load images for each dataset\n",
        "X_train = load_images(train_ids, IMAGE_FOLDER)\n",
        "X_val = load_images(val_ids, IMAGE_FOLDER)\n",
        "X_test = load_images(test_ids, IMAGE_FOLDER)\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "num_classes = len(unique_labels)\n",
        "y_train = to_categorical(y_train, num_classes=num_classes)\n",
        "y_val = to_categorical(y_val, num_classes=num_classes)\n",
        "y_test = to_categorical(y_test, num_classes=num_classes)\n",
        "\n",
        "# Debugging: Print dataset shapes\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbIbF9SsHJ-3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style for better visualization\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "# Display 15 sample images from the training set\n",
        "plt.figure(figsize=(15, 15))\n",
        "count = 1\n",
        "\n",
        "for i in range(15):  # Display first 15 images\n",
        "    img_name = train_ids.iloc[i]  # Get image filename\n",
        "    diagnosis = y_train[i].argmax()  # Convert one-hot encoded label back to class index\n",
        "\n",
        "    img_path = os.path.join(IMAGE_FOLDER, img_name)\n",
        "\n",
        "    if os.path.exists(img_path):\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
        "\n",
        "        plt.subplot(5, 5, count)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"ID: {img_name}\\nDiagnosis: {diagnosis}\")\n",
        "        plt.axis(\"off\")\n",
        "        count += 1\n",
        "    else:\n",
        "        print(f\"Warning: Image {img_path} not found!\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqR4yTJZH3BA"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Set style for better visualization\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "def visualize_samples(image_ids, data, labels, title, num_samples=15):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    count = 1\n",
        "\n",
        "    for i in range(min(num_samples, len(data))):\n",
        "        img = data[i]  # Get the image\n",
        "        img = (img * 255).astype(\"uint8\")  # Convert back to 8-bit format\n",
        "\n",
        "        label = labels[i].argmax()  # Convert one-hot encoded label back to class index\n",
        "        img_id = image_ids.iloc[i]  # Get corresponding image ID\n",
        "\n",
        "        plt.subplot(5, 5, count)\n",
        "        plt.imshow(img)  # Show correctly formatted image\n",
        "        plt.title(f\"ID: {img_id}\\nDiagnosis: {label}\", fontsize=10)\n",
        "        plt.axis(\"off\")\n",
        "        count += 1\n",
        "\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "# Visualize validation set\n",
        "visualize_samples(val_ids, X_val, y_val, \"Validation Set Samples\")\n",
        "\n",
        "# Visualize test set\n",
        "visualize_samples(test_ids, X_test, y_test, \"Test Set Samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz97_Lz-858y"
      },
      "source": [
        "# Train CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vQFE1Lr6xul"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def create_cnn(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    # Uncomment below to include the 512 layer block\n",
        "    # x = Conv2D(512, (3, 3), padding='same', activation='relu')(x)\n",
        "    # x = BatchNormalization()(x)\n",
        "    # x = Conv2D(512, (3, 3), activation='relu')(x)\n",
        "    # x = BatchNormalization()(x)\n",
        "    # x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    # x = Dropout(0.25)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Create CNN model\n",
        "cnn_model = create_cnn((IMG_HEIGHT, IMG_WIDTH, 3), len(unique_labels))\n",
        "\n",
        "# Train CNN model\n",
        "cnn_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),  # Use the predefined validation set\n",
        "    epochs=100,\n",
        "    batch_size=64\n",
        ")\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_acc = cnn_model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqUgEVaDyXJ2"
      },
      "outputs": [],
      "source": [
        "cnn_model.build((None, IMG_HEIGHT, IMG_WIDTH, 3))  # Ensure the model is built\n",
        "cnn_model.summary()  # Check the architecture\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Pv-vMX48_LZ"
      },
      "source": [
        "# Extract Features Using CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3TK9NjE-SCP4"
      },
      "outputs": [],
      "source": [
        "# Ensure the model is built and initialized\n",
        "cnn_model.predict(np.random.rand(1, IMG_HEIGHT, IMG_WIDTH, 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OR8HA8i4vRMq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Dummy data to run a forward pass and initialize the model\n",
        "dummy_input = np.random.rand(1, IMG_HEIGHT, IMG_WIDTH, 3).astype(np.float32)\n",
        "_ = cnn_model(dummy_input)  # This line initializes the model\n",
        "\n",
        "# Extract convolutional layers\n",
        "conv_layers = [layer for layer in cnn_model.layers if isinstance(layer, Conv2D)]\n",
        "\n",
        "# Now create feature extractor models\n",
        "feature_extractors = [Model(inputs=cnn_model.input, outputs=layer.output) for layer in conv_layers] # Now cnn_model.input is defined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3qg63v-eJ4bd"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np # Import numpy\n",
        "\n",
        "# Convert labels to integers\n",
        "y_train_labels = np.argmax(y_train, axis=1)\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Store results\n",
        "layer_accuracies = []\n",
        "\n",
        "# Define a smaller batch size for feature extraction\n",
        "batch_size = 64 # You can adjust this based on your GPU memory\n",
        "\n",
        "for i, extractor in enumerate(feature_extractors):\n",
        "    print(f\"\\nðŸ” Extracting features from Conv Layer {i+1}/{len(feature_extractors)}\")\n",
        "\n",
        "    # Extract features in batches\n",
        "    X_train_f = extractor.predict(X_train, batch_size=batch_size)\n",
        "    X_test_f = extractor.predict(X_test, batch_size=batch_size)\n",
        "\n",
        "\n",
        "    # Flatten\n",
        "    X_train_f = X_train_f.reshape(X_train_f.shape[0], -1)\n",
        "    X_test_f = X_test_f.reshape(X_test_f.shape[0], -1)\n",
        "\n",
        "    # Train Random Forest\n",
        "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf_model.fit(X_train_f, y_train_labels)\n",
        "\n",
        "    # Predict\n",
        "    preds = rf_model.predict(X_test_f)\n",
        "\n",
        "    # Evaluate\n",
        "    acc = accuracy_score(y_test_labels, preds)\n",
        "    print(f\"âœ… Accuracy using Conv Layer {i+1}: {acc:.4f}\")\n",
        "    layer_accuracies.append(acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8Qlz1c3Cuq5"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test_labels, preds)\n",
        "\n",
        "# Display confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "disp.plot(cmap=\"Blues\", values_format='d')\n",
        "plt.title(f\"Confusion Matrix - Conv Layer {i+1}\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6tXAf32LjOT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(range(1, len(layer_accuracies) + 1), layer_accuracies, marker='o')\n",
        "plt.xticks(range(1, len(layer_accuracies) + 1))\n",
        "plt.xlabel(\"Conv2D Layer Number\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Random Forest Accuracy vs. CNN Layer Features\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbnX8CiyJ4Hg"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NN_DRZkSD4m"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ensure the model is initialized\n",
        "cnn_model.predict(np.random.rand(1, IMG_HEIGHT, IMG_WIDTH, 3))  # Dummy input to initialize\n",
        "\n",
        "# Get all convolutional layers\n",
        "conv_layers = [layer for layer in cnn_model.layers if isinstance(layer, Conv2D)]\n",
        "\n",
        "# Create feature extractor models\n",
        "feature_extractors = [Model(inputs=cnn_model.input, outputs=layer.output) for layer in conv_layers]\n",
        "\n",
        "# Select a sample image (first image in X_train)\n",
        "sample_image = np.expand_dims(X_train[0], axis=0)  # Add batch dimension\n",
        "\n",
        "# Extract feature maps from all convolutional layers\n",
        "feature_maps_list = [extractor.predict(sample_image) for extractor in feature_extractors]\n",
        "\n",
        "# Function to plot feature maps\n",
        "def plot_all_feature_maps(feature_maps_list, conv_layers):\n",
        "    for feature_maps, layer in zip(feature_maps_list, conv_layers):\n",
        "        num_features = feature_maps.shape[-1]  # Number of feature maps (channels)\n",
        "        fig, axes = plt.subplots(1, min(8, num_features), figsize=(20, 20))\n",
        "        fig.suptitle(f'Feature Maps from Layer: {layer.name}', fontsize=16)\n",
        "\n",
        "        for i in range(min(8, num_features)):  # Show up to 8 feature maps\n",
        "            ax = axes[i]\n",
        "            ax.imshow(feature_maps[0, :, :, i], cmap='viridis')\n",
        "            ax.axis('off')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "# Visualize feature maps\n",
        "plot_all_feature_maps(feature_maps_list, conv_layers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4RSUrzh62u4"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Find the last fully connected dense layer before softmax\n",
        "feature_layer = None\n",
        "for layer in reversed(cnn_model.layers):\n",
        "    if isinstance(layer, Dense):  # Get last dense layer before softmax\n",
        "        feature_layer = layer\n",
        "        break\n",
        "\n",
        "# Create feature extractor model (excluding final softmax layer)\n",
        "feature_extractor = Model(inputs=cnn_model.input, outputs=feature_layer.output)\n",
        "\n",
        "# Extract features from train and test data\n",
        "X_train_features = feature_extractor.predict(X_train)\n",
        "X_test_features = feature_extractor.predict(X_test)\n",
        "\n",
        "# Convert labels back to integer format for Random Forest\n",
        "y_train_rf = np.argmax(y_train, axis=1)\n",
        "y_test_rf = np.argmax(y_test, axis=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gof3RBDH9DJ0"
      },
      "source": [
        "# Train Random Forest on Extracted Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xeVd0QPh7ymC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Predict\n",
        "y_pred_rf = rf_model.predict(X_test_features)\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test_rf, y_pred_rf)\n",
        "\n",
        "# Initialize sensitivity and specificity lists\n",
        "sensitivities = []\n",
        "specificities = []\n",
        "\n",
        "for i in range(len(cm)):\n",
        "    TP = cm[i, i]\n",
        "    FN = np.sum(cm[i, :]) - TP\n",
        "    FP = np.sum(cm[:, i]) - TP\n",
        "    TN = np.sum(cm) - (TP + FN + FP)\n",
        "\n",
        "    sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "\n",
        "    sensitivities.append(sensitivity)\n",
        "    specificities.append(specificity)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test_rf, y_pred_rf)\n",
        "\n",
        "# Print results\n",
        "print(f\"Random Forest Accuracy: {accuracy:.4f}\")\n",
        "for idx, (sens, spec) in enumerate(zip(sensitivities, specificities)):\n",
        "    print(f\"Class {idx}: Sensitivity = {sens:.4f}, Specificity = {spec:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wldltk258MId"
      },
      "source": [
        "#  Visualize Filters (Kernels) Learned by CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hv6K_uQj8O36"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Get first Conv2D layer filters\n",
        "for layer in cnn_model.layers:\n",
        "    if \"conv\" in layer.name:\n",
        "        filters, biases = layer.get_weights()\n",
        "        break\n",
        "\n",
        "# Normalize filter values to 0-1 for better display\n",
        "f_min, f_max = filters.min(), filters.max()\n",
        "filters = (filters - f_min) / (f_max - f_min)\n",
        "\n",
        "num_filters = filters.shape[3]\n",
        "num_channels = filters.shape[2]\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(nrows=4, ncols=8, figsize=(12, 6))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i in range(min(num_filters, 32)):  # Show up to 32 filters\n",
        "    ax = axes[i]\n",
        "    # Combine all channels as RGB if 3 channels\n",
        "    if num_channels == 3:\n",
        "        ax.imshow(filters[:, :, :, i])\n",
        "    else:\n",
        "        ax.imshow(filters[:, :, 0, i], cmap='gray')  # fallback to grayscale\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.suptitle(\"Filters from First Conv2D Layer\", fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYxoQcG_8ROD"
      },
      "source": [
        "# Visualize Feature Maps (Activations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGt6mA2M8V87"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Pick an image from test set\n",
        "sample_image = X_test[0]  # Pick first test image\n",
        "sample_image = np.expand_dims(sample_image, axis=0)  # Add batch dimension\n",
        "\n",
        "# Get a specific layer's output\n",
        "layer_outputs = [layer.output for layer in cnn_model.layers if \"conv\" in layer.name]\n",
        "visualization_model = Model(inputs=cnn_model.input, outputs=layer_outputs)\n",
        "\n",
        "# Get feature maps\n",
        "feature_maps = visualization_model.predict(sample_image)\n",
        "\n",
        "# Plot feature maps of the first Conv2D layer\n",
        "fig, axes = plt.subplots(nrows=4, ncols=8, figsize=(12, 6))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i in range(min(len(feature_maps[0][0, :, :, :]), 32)):  # Show first 32 feature maps\n",
        "    ax = axes[i]\n",
        "    ax.imshow(feature_maps[0][0, :, :, i], cmap=\"viridis\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqNWoZA98YiD"
      },
      "source": [
        "# Project Features Using PCA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8iEpWmq8bkz"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import seaborn as sns\n",
        "\n",
        "# Perform PCA on extracted features\n",
        "pca = PCA(n_components=2)\n",
        "X_train_pca = pca.fit_transform(X_train_features)\n",
        "\n",
        "# Scatter plot of the features\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.scatterplot(x=X_train_pca[:, 0], y=X_train_pca[:, 1], hue=y_train_rf, palette=\"viridis\")\n",
        "plt.xlabel(\"Principal Component 1\")\n",
        "plt.ylabel(\"Principal Component 2\")\n",
        "plt.title(\"PCA Visualization of Extracted Features\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8itA8xM58dly"
      },
      "source": [
        "# Evaluate Features with Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fIj_tLM8l1k"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test_rf, y_pred_rf))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuDZ6Oyp8oHf"
      },
      "source": [
        "#  Generate Class Activation Maps (CAMs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0X6PuU68svX"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.backend as K\n",
        "import cv2\n",
        "\n",
        "# Pick a test image\n",
        "img = X_test[0]\n",
        "img = np.expand_dims(img, axis=0)\n",
        "\n",
        "# Get model predictions\n",
        "preds = cnn_model.predict(img)\n",
        "pred_class = np.argmax(preds[0])  # Get highest probability class\n",
        "\n",
        "# Get last convolutional layer by name\n",
        "# Instead of using a hardcoded name, find the last Conv2D layer:\n",
        "last_conv_layer = None\n",
        "for layer in reversed(cnn_model.layers):  # Iterate in reverse order\n",
        "    if isinstance(layer, Conv2D):\n",
        "        last_conv_layer = layer\n",
        "        break\n",
        "\n",
        "# If no convolutional layer was found, raise an error\n",
        "if last_conv_layer is None:\n",
        "    raise ValueError(\"No convolutional layers found in the model!\")\n",
        "\n",
        "# Get gradients of predicted class wrt feature maps\n",
        "grad_model = Model(inputs=cnn_model.input, outputs=[last_conv_layer.output, cnn_model.output])\n",
        "with tf.GradientTape() as tape:\n",
        "    conv_output, predictions = grad_model(img)\n",
        "    loss = predictions[:, pred_class]\n",
        "\n",
        "grads = tape.gradient(loss, conv_output)\n",
        "pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "# Apply gradients to feature map\n",
        "heatmap = np.mean(conv_output[0], axis=-1)\n",
        "heatmap = np.maximum(heatmap, 0)  # Apply ReLU\n",
        "heatmap /= np.max(heatmap)  # Normalize\n",
        "\n",
        "# Superimpose heatmap on image\n",
        "# Replace 'TEST_IMAGE_FOLDER' and 'test_ids.iloc[0]' with your actual image path\n",
        "# img = cv2.imread(TEST_IMAGE_FOLDER + test_ids.iloc[0])\n",
        "img = X_test[0] * 255 #Assuming X_test is normalized, convert it back to 0-255 range\n",
        "img = img.astype(np.uint8) # Convert to uint8 for cv2 compatibility\n",
        "img = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n",
        "\n",
        "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "heatmap = np.uint8(255 * heatmap)\n",
        "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "superimposed_img = cv2.addWeighted(img, 0.6, heatmap, 0.4, 0)\n",
        "plt.imshow(superimposed_img)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c91a731b"
      },
      "source": [
        "# Plot Accuracy and Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2d280dea"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get training history\n",
        "history = cnn_model.history.history\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history['loss'], label='Training Loss')\n",
        "plt.plot(history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R58nng8Ge08S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e69558d"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.decomposition import PCA\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# --- 1. Setup and Data Loading --- #\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATA_CSV = \"/content/train.csv\"\n",
        "ZIP_PATH = \"/content/drive/MyDrive/train_images.zip\"\n",
        "IMAGE_FOLDER = \"/content/train_images\"\n",
        "\n",
        "if not os.path.exists(IMAGE_FOLDER):\n",
        "    with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
        "        zip_ref.extractall(IMAGE_FOLDER)\n",
        "\n",
        "full_df = pd.read_csv(DATA_CSV)\n",
        "full_df[\"id_code\"] = full_df[\"id_code\"].astype(str) + \".png\"\n",
        "labels = full_df[\"diagnosis\"]\n",
        "\n",
        "unique_labels = sorted(labels.unique())\n",
        "label_to_index = {label: idx for idx, label in enumerate(unique_labels)}\n",
        "labels_encoded = np.array([label_to_index[label] for label in labels])\n",
        "\n",
        "train_ids, temp_ids, y_train_idx, y_temp_idx = train_test_split(full_df[\"id_code\"], labels_encoded, test_size=0.3, random_state=42)\n",
        "val_ids, test_ids, y_val_idx, y_test_idx = train_test_split(temp_ids, y_temp_idx, test_size=0.5, random_state=42)\n",
        "\n",
        "IMG_HEIGHT, IMG_WIDTH = 128, 128\n",
        "\n",
        "def load_images(image_ids, image_folder):\n",
        "    images = []\n",
        "    for img_id in image_ids:\n",
        "        img_path = os.path.join(image_folder, img_id)\n",
        "        if os.path.exists(img_path):\n",
        "            img = load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
        "            img = img_to_array(img) / 255.0\n",
        "            images.append(img)\n",
        "        else:\n",
        "            print(f\"Warning: Image {img_path} not found!\")\n",
        "    return np.array(images)\n",
        "\n",
        "X_train = load_images(train_ids, IMAGE_FOLDER)\n",
        "X_val = load_images(val_ids, IMAGE_FOLDER)\n",
        "X_test = load_images(test_ids, IMAGE_FOLDER)\n",
        "\n",
        "num_classes = len(unique_labels)\n",
        "y_train = to_categorical(y_train_idx, num_classes=num_classes)\n",
        "y_val = to_categorical(y_val_idx, num_classes=num_classes)\n",
        "y_test = to_categorical(y_test_idx, num_classes=num_classes)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
        "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
        "\n",
        "# --- 2. Initial Data Visualization --- #\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "for i in range(15):\n",
        "    img_name = train_ids.iloc[i]\n",
        "    diagnosis = y_train[i].argmax()\n",
        "    img_path = os.path.join(IMAGE_FOLDER, img_name)\n",
        "    if os.path.exists(img_path):\n",
        "        img = cv2.imread(img_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        plt.subplot(5, 5, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"ID: {img_name}\\nDiagnosis: {diagnosis}\")\n",
        "        plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "def visualize_samples(image_ids, data, labels, title, num_samples=15):\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    for i in range(min(num_samples, len(data))):\n",
        "        img = (data[i] * 255).astype(\"uint8\")\n",
        "        label = labels[i].argmax()\n",
        "        img_id = image_ids.iloc[i]\n",
        "        plt.subplot(5, 5, i + 1)\n",
        "        plt.imshow(img)\n",
        "        plt.title(f\"ID: {img_id}\\nDiagnosis: {label}\", fontsize=10)\n",
        "        plt.axis(\"off\")\n",
        "    plt.suptitle(title, fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "visualize_samples(val_ids, X_val, y_val, \"Validation Set Samples\")\n",
        "visualize_samples(test_ids, X_test, y_test, \"Test Set Samples\")\n",
        "\n",
        "# --- 3. CNN Model Definition and Training --- #\n",
        "def create_cnn(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(32, (3, 3), activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    x = Dropout(0.25)(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "cnn_model = create_cnn((IMG_HEIGHT, IMG_WIDTH, 3), num_classes)\n",
        "\n",
        "# Train CNN model\n",
        "history = cnn_model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "test_loss, test_acc = cnn_model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
        "\n",
        "cnn_model.build((None, IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "cnn_model.summary()\n",
        "\n",
        "# --- 4. Plot Training History --- #\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# --- 5. Feature Extraction with Random Forest on Conv Layers --- #\n",
        "# Dummy input to ensure model is fully built before creating feature extractors\n",
        "_ = cnn_model.predict(np.random.rand(1, IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "conv_layers = [layer for layer in cnn_model.layers if isinstance(layer, Conv2D)]\n",
        "feature_extractors_conv = [Model(inputs=cnn_model.input, outputs=layer.output) for layer in conv_layers]\n",
        "\n",
        "y_train_labels = np.argmax(y_train, axis=1)\n",
        "y_test_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "layer_accuracies = []\n",
        "batch_size = 64\n",
        "last_conv_preds = None # To store predictions for the last conv layer for CM\n",
        "last_conv_idx = 0 # To store the index for the CM title\n",
        "\n",
        "for i, extractor in enumerate(feature_extractors_conv):\n",
        "    print(f\"\\nðŸ” Extracting features from Conv Layer {i+1}/{len(feature_extractors_conv)}\")\n",
        "    X_train_f = extractor.predict(X_train, batch_size=batch_size)\n",
        "    X_test_f = extractor.predict(X_test, batch_size=batch_size)\n",
        "\n",
        "    X_train_f = X_train_f.reshape(X_train_f.shape[0], -1)\n",
        "    X_test_f = X_test_f.reshape(X_test_f.shape[0], -1)\n",
        "\n",
        "    rf_model_conv = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf_model_conv.fit(X_train_f, y_train_labels)\n",
        "\n",
        "    preds_conv = rf_model_conv.predict(X_test_f)\n",
        "    acc = accuracy_score(y_test_labels, preds_conv)\n",
        "    print(f\"âœ… Accuracy using Conv Layer {i+1}: {acc:.4f}\")\n",
        "    layer_accuracies.append(acc)\n",
        "\n",
        "    if i == len(feature_extractors_conv) - 1:\n",
        "        last_conv_preds = preds_conv\n",
        "        last_conv_idx = i + 1\n",
        "\n",
        "# Plot RF Accuracy vs. CNN Layer Features\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(range(1, len(layer_accuracies) + 1), layer_accuracies, marker='o')\n",
        "plt.xticks(range(1, len(layer_accuracies) + 1))\n",
        "plt.xlabel(\"Conv2D Layer Number\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Random Forest Accuracy vs. CNN Layer Features\")\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Confusion matrix for the last convolutional layer's features\n",
        "if last_conv_preds is not None:\n",
        "    cm_conv = confusion_matrix(y_test_labels, last_conv_preds)\n",
        "    disp_conv = ConfusionMatrixDisplay(confusion_matrix=cm_conv, display_labels=unique_labels)\n",
        "    disp_conv.plot(cmap=\"Blues\", values_format='d')\n",
        "    plt.title(f\"Confusion Matrix - RF on Features from Conv Layer {last_conv_idx}\")\n",
        "    plt.show()\n",
        "\n",
        "# --- 6. Feature Extraction with Random Forest on Last Dense Layer --- #\n",
        "feature_layer = None\n",
        "for layer in reversed(cnn_model.layers):\n",
        "    if isinstance(layer, Dense) and layer.activation.__name__ != 'softmax': # Get last dense layer before softmax\n",
        "        feature_layer = layer\n",
        "        break\n",
        "\n",
        "if feature_layer is None:\n",
        "    print(\"Error: No suitable dense layer found for feature extraction.\")\n",
        "else:\n",
        "    feature_extractor_dense = Model(inputs=cnn_model.input, outputs=feature_layer.output)\n",
        "\n",
        "    X_train_features_dense = feature_extractor_dense.predict(X_train)\n",
        "    X_test_features_dense = feature_extractor_dense.predict(X_test)\n",
        "\n",
        "    y_train_rf = np.argmax(y_train, axis=1)\n",
        "    y_test_rf = np.argmax(y_test, axis=1)\n",
        "\n",
        "    rf_model_dense = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf_model_dense.fit(X_train_features_dense, y_train_rf)\n",
        "\n",
        "    y_pred_rf_dense = rf_model_dense.predict(X_test_features_dense)\n",
        "\n",
        "    print(f\"\\n--- Evaluation for Random Forest on Last Dense Layer Features ---\")\n",
        "    accuracy_dense = accuracy_score(y_test_rf, y_pred_rf_dense)\n",
        "    print(f\"Random Forest Accuracy: {accuracy_dense:.4f}\")\n",
        "\n",
        "    cm_dense = confusion_matrix(y_test_rf, y_pred_rf_dense)\n",
        "    sensitivities = []\n",
        "    specificities = []\n",
        "\n",
        "    for i in range(len(cm_dense)):\n",
        "        TP = cm_dense[i, i]\n",
        "        FN = np.sum(cm_dense[i, :]) - TP\n",
        "        FP = np.sum(cm_dense[:, i]) - TP\n",
        "        TN = np.sum(cm_dense) - (TP + FN + FP)\n",
        "\n",
        "        sensitivity = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "        specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
        "\n",
        "        sensitivities.append(sensitivity)\n",
        "        specificities.append(specificity)\n",
        "\n",
        "    for idx, (sens, spec) in enumerate(zip(sensitivities, specificities)):\n",
        "        print(f\"Class {idx}: Sensitivity = {sens:.4f}, Specificity = {spec:.4f}\")\n",
        "\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test_rf, y_pred_rf_dense, target_names=[str(l) for l in unique_labels]))\n",
        "\n",
        "    disp_dense = ConfusionMatrixDisplay(confusion_matrix=cm_dense, display_labels=unique_labels)\n",
        "    disp_dense.plot(cmap=\"Blues\", values_format='d')\n",
        "    plt.title(\"Confusion Matrix - RF on Last Dense Layer Features\")\n",
        "    plt.show()\n",
        "\n",
        "# --- 7. Visualize Filters (Kernels) Learned by CNN --- #\n",
        "filters = None\n",
        "for layer in cnn_model.layers:\n",
        "    if isinstance(layer, Conv2D):\n",
        "        filters, biases = layer.get_weights()\n",
        "        break\n",
        "\n",
        "if filters is not None:\n",
        "    f_min, f_max = filters.min(), filters.max()\n",
        "    filters = (filters - f_min) / (f_max - f_min)\n",
        "\n",
        "    num_filters = filters.shape[3]\n",
        "    num_channels = filters.shape[2]\n",
        "\n",
        "    fig, axes = plt.subplots(nrows=4, ncols=8, figsize=(12, 6))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i in range(min(num_filters, 32)):\n",
        "        ax = axes[i]\n",
        "        if num_channels == 3:\n",
        "            ax.imshow(filters[:, :, :, i])\n",
        "        else:\n",
        "            ax.imshow(filters[:, :, 0, i], cmap='gray')\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    plt.suptitle(\"Filters from First Conv2D Layer\", fontsize=14)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No convolutional filters found to visualize.\")\n",
        "\n",
        "\n",
        "# --- 8. Visualize Feature Maps (Activations) --- #\n",
        "sample_image_vis = np.expand_dims(X_test[0], axis=0)\n",
        "\n",
        "layer_outputs_vis = [layer.output for layer in cnn_model.layers if isinstance(layer, Conv2D)]\n",
        "visualization_model = Model(inputs=cnn_model.input, outputs=layer_outputs_vis)\n",
        "\n",
        "feature_maps_vis = visualization_model.predict(sample_image_vis)\n",
        "\n",
        "fig, axes = plt.subplots(nrows=4, ncols=8, figsize=(12, 6))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i in range(min(feature_maps_vis[0].shape[-1], 32)):\n",
        "    ax = axes[i]\n",
        "    ax.imshow(feature_maps_vis[0][0, :, :, i], cmap=\"viridis\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "plt.suptitle(f'Feature Maps from Layer: {conv_layers[0].name}', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- 9. Project Features Using PCA (from last dense layer features) --- #\n",
        "if feature_layer is not None:\n",
        "    pca = PCA(n_components=2)\n",
        "    X_train_pca = pca.fit_transform(X_train_features_dense)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.scatterplot(x=X_train_pca[:, 0], y=X_train_pca[:, 1], hue=y_train_rf, palette=\"viridis\", legend='full')\n",
        "    plt.xlabel(\"Principal Component 1\")\n",
        "    plt.ylabel(\"Principal Component 2\")\n",
        "    plt.title(\"PCA Visualization of Extracted Features (from last dense layer)\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Cannot perform PCA as last dense layer features were not extracted.\")\n",
        "\n",
        "# --- 10. Generate Class Activation Maps (CAMs) --- #\n",
        "img_for_cam = X_test[0]\n",
        "img_for_cam_expanded = np.expand_dims(img_for_cam, axis=0)\n",
        "\n",
        "preds_cam = cnn_model.predict(img_for_cam_expanded)\n",
        "pred_class_cam = np.argmax(preds_cam[0])\n",
        "\n",
        "last_conv_layer_cam = None\n",
        "for layer in reversed(cnn_model.layers):\n",
        "    if isinstance(layer, Conv2D):\n",
        "        last_conv_layer_cam = layer\n",
        "        break\n",
        "\n",
        "if last_conv_layer_cam is None:\n",
        "    print(\"Error: No convolutional layers found in the model for CAM!\")\n",
        "else:\n",
        "    grad_model_cam = Model(inputs=cnn_model.input, outputs=[last_conv_layer_cam.output, cnn_model.output])\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_output_cam, predictions_cam = grad_model_cam(img_for_cam_expanded)\n",
        "        loss_cam = predictions_cam[:, pred_class_cam]\n",
        "\n",
        "    grads_cam = tape.gradient(loss_cam, conv_output_cam)\n",
        "    pooled_grads_cam = K.mean(grads_cam, axis=(0, 1, 2))\n",
        "\n",
        "    heatmap_cam = np.mean(conv_output_cam[0], axis=-1)\n",
        "    heatmap_cam = np.maximum(heatmap_cam, 0)\n",
        "    if np.max(heatmap_cam) > 0: # Avoid division by zero\n",
        "        heatmap_cam /= np.max(heatmap_cam)\n",
        "\n",
        "    img_display_cam = (img_for_cam * 255).astype(np.uint8)\n",
        "    img_display_cam = cv2.resize(img_display_cam, (IMG_HEIGHT, IMG_WIDTH))\n",
        "\n",
        "    heatmap_cam = cv2.resize(heatmap_cam, (img_display_cam.shape[1], img_display_cam.shape[0]))\n",
        "    heatmap_cam = np.uint8(255 * heatmap_cam)\n",
        "    heatmap_cam = cv2.applyColorMap(heatmap_cam, cv2.COLORMAP_JET)\n",
        "\n",
        "    superimposed_img_cam = cv2.addWeighted(img_display_cam, 0.6, heatmap_cam, 0.4, 0)\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.imshow(cv2.cvtColor(superimposed_img_cam, cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f\"CAM for Predicted Class: {pred_class_cam}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}